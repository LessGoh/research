# Streamlit Secrets Configuration Template
# Copy this file to .streamlit/secrets.toml and fill in your actual API keys
# NEVER commit the actual secrets.toml file to version control

[api_keys]
# OpenAI API Key for response generation
# Get from: https://platform.openai.com/api-keys
openai_api_key = "sk-proj-your-actual-openai-api-key-here"

# LlamaCloud API Key for index access
# Get from: https://cloud.llamaindex.ai/
llamacloud_api_key = "llx-your-actual-llamacloud-api-key-here"

[llamacloud]
# LlamaCloud configuration (optional - these are defaults in config.py)
organization_id = "858afa1e-d3dc-4a96-8783-d4f3798b0643"
index_name = "Arxiv 2024-2025. Key: Volatility / Parsing Preset: Balanced, Chunk size: 256, Chunk Overlap: 50"
project_name = "Default"

[app_settings]
# Optional app-level settings (can override config.py defaults)
default_top_k = 3
default_temperature = 0.2
max_tokens = 1000
enable_debug = false

[ui_settings]
# Optional UI customization
page_title = "Research Q/A Bot"
page_icon = "ðŸ”¬"
sidebar_state = "expanded"

# Instructions:
# 1. Copy this file to .streamlit/secrets.toml
# 2. Replace the placeholder values with your actual API keys
# 3. The .streamlit/secrets.toml file is already excluded in .gitignore
# 4. For Streamlit Cloud deployment, add these secrets through the web interface
